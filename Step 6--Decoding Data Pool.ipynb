{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c588b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reads: 14121\n",
      "This is Chapter 12\n",
      "We provide a simple description of the most general collective Gaussian attack in continuous-variable quantum cryptography. In the scenario of such general attacks, we analyze the asymptotic secret-key rates which are achievable with coherent states, joint measurements of the quadratures and one-way classical communication.\n",
      "This is Chapter 14\n",
      "Device-independent cryptography goes beyond conventional quantum cryptography by providing security that holds independently of the quality of the underlying physical devices. Device-independent protocols are based on the quantum phenomena of non-locality and the violation of Bell inequalities. This high level of security could so far only be established under conditions which are not achievable experimentally. Here we present a property of entropy, termed \"entropy accumulation\", which asserts that the total amount of entropy of a large system is the sum of its parts. We use this property to prove the security of cryptographic protocols, including device-independent quantum key distribution, while achieving essentially optimal parameters. Recent experimental progress, which enabled loophole-free Bell tests, suggests that the achieved parameters are technologically accessible. Our work hence provides the theoretical groundwork for experimental demonstrations of device-independent cryptography. \n",
      "This is Chapter 17\n",
      "Visual cryptography encodes a secret binary image (SI) into n shares of random binary patterns. If the shares are xeroxed onto transparencies, the secret image can be visually decoded by superimposing a qualified subset of transparencies, but no secret information can be obtained from the superposition of a forbidden subset. The binary patterns of the n shares, however, have no visual meaning and hinder the objectives of visual cryptography. Extended visual cryptography was proposed recently to construct meaningful binary images as shares using hypergraph colourings, but the visual quality is poor. In this paper, a novel technique named halftone visual cryptography is proposed to achieve visual cryptography via halftoning. Based on the blue-noise dithering principles, the proposed method utilizes the void and cluster algorithm to encode a secret binary image into n halftone shares (images) carrying significant visual information. The simulation shows that the visual quality of the obtained halftone shares are observably better than that attained by any available visual cryptography method known to date. \n",
      "This is Chapter 31\n",
      "Biomolecular cryptography exploiting specific biomolecular interactions for data encryption represents a unique approach for information security. However, constructing protocols based on biomolecular reactions to guarantee confidentiality, integrity and availability (CIA) of information remains a challenge. Here we develop DNA origami cryptography (DOC) that exploits folding of a M13 viral scaffold into nanometer-scale self-assembled braille-like patterns for secure communication, which can create a key with a size of over 700 bits. The intrinsic nanoscale addressability of DNA origami additionally allows for protein binding-based steganography, which further protects message confidentiality in DOC. The integrity of a transmitted message can be ensured by establishing specific linkages between several DNA origamis carrying parts of the message. The versatility of DOC is further demonstrated by transmitting various data formats including text, musical notes and images, supporting its great potential for meeting the rapidly increasing CIA demands of next-generation cryptography. \n",
      "This is Chapter 36\n",
      "Quantum key distribution (QKD) is a theoretically secure way of sharing secret keys between remote users. It has been demonstrated in a laboratory over a coiled optical fibre up to 404 kilometres long. In the field, point-to-point QKD has been achieved from a satellite to a ground station up to 1,200 kilometres away. However, real-world QKD-based cryptography targets physically separated users on the Earth, for which the maximum distance has been about 100 kilometres. The use of trusted relays can extend these distances from across a typical metropolitan area to intercity and even intercontinental distances. However, relays pose security risks, which can be avoided by using entanglement-based QKD, which has inherent source-independent security. Long-distance entanglement distribution can be realized using quantum repeaters, but the related technology is still immature for practical implementations. The obvious alternative for extending the range of quantum communication without compromising its security is satellite-based QKD, but so far satellite-based entanglement distribution has not been efficient enough to support QKD. Here we demonstrate entanglement-based QKD between two ground stations separated by 1,120 kilometres at a finite secret-key rate of 0.12 bits per second, without the need for trusted relays. Entangled photon pairs were distributed via two bidirectional downlinks from the Micius satellite to two ground observatories in Delingha and Nanshan in China. The development of a high-efficiency telescope and follow-up optics crucially improved the link efficiency. The generated keys are secure for realistic devices, because our ground receivers were carefully designed to guarantee fair sampling and immunity to all known side channels. Our method not only increases the secure distance on the ground tenfold but also increases the practical security of QKD to an unprecedented level. \n",
      "Chapter 12 is found\n",
      "Last segment is 11\n",
      "Chapter 14 is found\n",
      "Last segment is 36\n",
      "Chapter 17 is found\n",
      "Last segment is 40\n",
      "Chapter 31 is found\n",
      "Last segment is 38\n",
      "Chapter 36 is found\n",
      "Last segment is 66\n",
      "Total number of valid reads: 12736\n",
      "Exact matched sequences before RS correction: 9693\n",
      "Matched sequences after RS correction: 10425\n"
     ]
    }
   ],
   "source": [
    "# This program aims to process the data sequences and translate them into ascii texts\n",
    "# Data sequence processing workflow:\n",
    "# 1. Identify and exclude PCR primers. The PCR primers also corresponds to the Chapter number.\n",
    "# 2. RS correcting the data sequence and extract data sequence.\n",
    "# 3. Decode segment number (the first four bases after forward primer).\n",
    "# 4. Convert data sequence to hex data.\n",
    "# 5. Convert hex data to texts\n",
    "\n",
    "\n",
    "from reedsolo import RSCodec, ReedSolomonError\n",
    "\n",
    "rsc = RSCodec(2)\n",
    "\n",
    "%store -r primerLibrary\n",
    "%store -r referenceStrands\n",
    "%store -r array_data_payload\n",
    "\n",
    "def converter(seq):\n",
    "    converter = {'A': '00', 'C': '01', 'G': '10', 'T': '11'} \n",
    "    bases = list(seq) \n",
    "    bases = [converter[base] for base in bases] \n",
    "    return ''.join(bases)\n",
    "\n",
    "def deconverter(seq):\n",
    "    deconverter = {'00': 'A', '01': 'C', '10': 'G', '11': 'T'} \n",
    "    doubleBits = [seq[i:i+2] for i in range(0, len(seq), 2)]\n",
    "    doubleBits = [deconverter[doubleBit] for doubleBit in doubleBits] \n",
    "    return ''.join(doubleBits)\n",
    "\n",
    "def oligoToBase3(seq):\n",
    "    oligoToBase3 = {'G': '0', 'T': '1', 'A': '2', 'C': '3', 'N': '3'}\n",
    "    oligoToBase3Converted = []\n",
    "    for i in range (0, len(seq)):\n",
    "        if (oligoToBase3[seq[i]] == '3'):\n",
    "            return -1\n",
    "        else:\n",
    "            oligoToBase3Converted.append(oligoToBase3[seq[i]])\n",
    "            if seq[i] == 'C':\n",
    "                oligoToBase3 = {'G': '0', 'T': '1', 'A': '2', 'C': '3', 'N': '3'}\n",
    "            elif seq[i] == 'G':\n",
    "                oligoToBase3 = {'T': '0', 'A': '1', 'C': '2', 'G': '3', 'N': '3'}\n",
    "            elif seq[i] == 'T':\n",
    "                oligoToBase3 = {'A': '0', 'C': '1', 'G': '2', 'T': '3', 'N': '3'}\n",
    "            elif seq[i] == 'A':\n",
    "                oligoToBase3 = {'C': '0', 'G': '1', 'T': '2', 'A': '3', 'N': '3'}\n",
    "\n",
    "\n",
    "    return ''.join(oligoToBase3Converted)\n",
    "\n",
    "def ternaryToDecimal(n):\n",
    "    decimal = 0\n",
    "    n = ''.join(reversed(n))\n",
    "    for i in range (0, len(n)):\n",
    "        decimal += (int(n[i]))*(pow(3, i))\n",
    "    return decimal\n",
    "\n",
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    string = List[0]\n",
    "     \n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            string = i\n",
    "            \n",
    "    return string\n",
    "\n",
    "def binaryToHex(binary_string):\n",
    "    decimal_representation = int(binary_string, 2)\n",
    "    hexadecimal_string = hex(decimal_representation)\n",
    "    return hexadecimal_string\n",
    "\n",
    "def hexToText(hex_string):\n",
    "    hex_string = hex_string[2:]\n",
    "    bytes_object = bytes.fromhex(hex_string)\n",
    "    ascii_string = bytes_object.decode(\"utf-8\")\n",
    "    return ascii_string\n",
    "\n",
    "\n",
    "\n",
    "%store -r array_data\n",
    "\n",
    "# Read input FASTQ file\n",
    "file_R1 = open('amplicon-3_S5_L001_R1_001.fastq', 'r')\n",
    "file_R2 = open('amplicon-3_S5_L001_R2_001.fastq', 'r')\n",
    "\n",
    "Lines_R1 = file_R1.readlines()\n",
    "Lines_R2 = file_R2.readlines()\n",
    "\n",
    "new_Lines_R1 = []\n",
    "new_Lines_R2 = []\n",
    "\n",
    "complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n",
    "\n",
    "for i in range (0, int(len(Lines_R1))):\n",
    "    if i%4 == 1:\n",
    "        new_Lines_R1.append(Lines_R1[i][0:151].strip('\\n'))\n",
    "\n",
    "for i in range (0, int(len(Lines_R2))):\n",
    "    if i%4 == 1:\n",
    "        reverse_complement_R2 = \"\".join(complement.get(base, base) for base in reversed(Lines_R2[i][0:151].strip('\\n')))\n",
    "        new_Lines_R2.append(reverse_complement_R2)\n",
    "\n",
    "print('Total number of reads: ' + str(len(new_Lines_R1)))\n",
    "\n",
    "new_Lines_Combo = []\n",
    "\n",
    "# Define a list to store Read Number of those reads which passed the following conditions:\n",
    "read_index_1 = []\n",
    "\n",
    "for i in range (0, len(new_Lines_R1)):\n",
    "    \n",
    "    # Pick out those with 149-nt read overlap \n",
    "    if (new_Lines_R1[i][0:149] == new_Lines_R2[i][0:149]): # Ensure paired-end read generates consistent results.\n",
    "        new_Lines_Combo.append(new_Lines_R1[i][0:149])\n",
    "        read_index_1.append(i)\n",
    "        \n",
    "    # If the length of payload is exactly 142 nt, some reads may be excluded from the above condition because they have mismatches outside payload region.\n",
    "    # Then we should pick out those with 142-nt read overlap. \n",
    "    elif (new_Lines_R1[i][0:142] == new_Lines_R2[i][0:142]): # Ensure paired-end read generates consistent results.\n",
    "        new_Lines_Combo.append(new_Lines_R1[i][0:142])\n",
    "        read_index_1.append(i)\n",
    "\n",
    "    # If payload is longer than 151 nt, then we have to find overlap between the two reads\n",
    "    else:                                  \n",
    "        for j in range (0, len(new_Lines_R1[i])):\n",
    "            if (new_Lines_R1[i][j:] == new_Lines_R2[i][0:len(new_Lines_R1[i])-j]): # Detecting maximal overlapped region\n",
    "                new_Lines_Combo_Unit = new_Lines_R1[i] + new_Lines_R2[i][-(j+len(new_Lines_R2[i])-len(new_Lines_R1[i])):]\n",
    "\n",
    "                # Exclude those longer than 170 nt.\n",
    "                if len(new_Lines_Combo_Unit) > 170:\n",
    "                    continue \n",
    "\n",
    "                new_Lines_Combo.append(new_Lines_Combo_Unit)\n",
    "                read_index_1.append(i)\n",
    "                break\n",
    "        \n",
    "        \n",
    "Lines = new_Lines_Combo\n",
    "\n",
    "# Get the number of valid reads\n",
    "res_read_index_1 = [*set(read_index_1)]\n",
    "\n",
    "\n",
    "primerLength = 21\n",
    "dataStrandsOccup = [[None]*100 for _ in range(40)]\n",
    "dataStrandstoText = [[None]*100 for _ in range(40)]\n",
    "dataStrands = [[None]*100 for _ in range(40)]\n",
    "candi_dataStrands = [ [ [] for i in range(100) ] for i in range(40) ]\n",
    "\n",
    "RS_before = 0\n",
    "RS_after = 0\n",
    "read_index_2 = []\n",
    "read_index_3 = []\n",
    "\n",
    "read_number = -1\n",
    "\n",
    "for data in Lines:\n",
    "    read_number += 1\n",
    "    data = data.strip('\\n')   # In '.txt' files, there may be '\\n' symbols meaning the start of a new line. Those symbols needs to be eliminated. \n",
    "    # Extract forward and reverse PCR primer sequence and identify the Chapter Number\n",
    "    chapterStartSequence = data[0:primerLength]\n",
    "    chapterEndSequence = data[(len(data) - primerLength):]\n",
    "    try:\n",
    "        chapterStart = primerLibrary.index(chapterStartSequence)\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        chapterEnd = primerLibrary.index(chapterEndSequence)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    chapterEnd = len(primerLibrary) - chapterEnd - 1\n",
    "    if (chapterStart == chapterEnd):\n",
    "        Chapter = chapterStart\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    data = data[primerLength:(len(data)-primerLength)]\n",
    "    # Count matched sequence before RS correction\n",
    "    for m in range (0, 40):\n",
    "        for n in range (0, 100):\n",
    "            if data == array_data[m][n]:\n",
    "                read_index_2.append(read_index_1[read_number])   # Store Read Number with successful decoding attempt before RS correction\n",
    "    \n",
    "    RS = data[-12:]  # Extract RS Sequence (base-3)\n",
    "    \n",
    "    data_to_be_modulated = data[4:(len(data)-12)]\n",
    "    data_modulated = ''\n",
    "    for i in range (0, int(len(data_to_be_modulated)/7)):\n",
    "        data_modulated_segment = data_to_be_modulated[i*7:(i+1)*7]\n",
    "        data_modulated_segment = data_modulated_segment + data_to_be_modulated[i*7+6]  # Add one more Pointer Base to make the sequence checkable by RS\n",
    "        data_modulated = data_modulated + data_modulated_segment\n",
    "        data_modulated_segment = ''\n",
    "    \n",
    "    data = data[0:4] + data_modulated\n",
    "    \n",
    "    # Convert RS Sequence to ternary number, then to binary number\n",
    "    RS_segment_binary_total = []\n",
    "    for i in range (0, int(len(RS)/6)):\n",
    "        RS_segment = RS[i*6:(i+1)*6]\n",
    "        RS_segment_base3 = oligoToBase3(RS_segment)\n",
    "        if (RS_segment_base3 == -1):\n",
    "            break\n",
    "        RS_segment_decimal = ternaryToDecimal(RS_segment_base3)\n",
    "        RS_segment_binary = bin(RS_segment_decimal)\n",
    "        RS_segment_binary = RS_segment_binary[2:]\n",
    "        RS_segment_binary = '0'*(8-len(RS_segment_binary)) + RS_segment_binary\n",
    "        RS_segment_binary = str(RS_segment_binary)\n",
    "        RS_segment_binary_total.append(RS_segment_binary)\n",
    "    RS_segment_binary_total = ''.join(RS_segment_binary_total)\n",
    "\n",
    "    if (len(RS_segment_binary_total) != 16):\n",
    "        continue\n",
    "    \n",
    "    binaryConverted = converter(data)    # Convert Data Sequence to binary number \n",
    "    binaryConverted = binaryConverted + RS_segment_binary_total  # Combine the data and RS code in binary form\n",
    "\n",
    "    binaryList = [int(binaryConverted[i:i + 8], 2) for i in range(0, len(binaryConverted), 8)]\n",
    "    bytesList = bytes(binaryList)\n",
    "\n",
    "    try:\n",
    "        RSDecoded = rsc.decode(bytesList)[0]   # RS correction\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    bytes_as_bits = ''.join(format(byte, '08b') for byte in RSDecoded)\n",
    "    baseDeconverted = deconverter(bytes_as_bits)   # Convert corrected bytes back to DNA sequences \n",
    "    # Extract and identify Segment Number\n",
    "    segmentSequence = baseDeconverted[0:4]   \n",
    "    segmentBase3 = oligoToBase3(segmentSequence)\n",
    "    if (segmentBase3 == -1):\n",
    "        continue\n",
    "    segmentBase10 = ternaryToDecimal(segmentBase3)\n",
    "    Segment = segmentBase10\n",
    "\n",
    "    \n",
    "    # In each segment, get Index Bases and Pointer Base in 8-nt unit\n",
    "    baseDeconverted = baseDeconverted[4:]\n",
    "    corrected_data = ''\n",
    "    characterLength = int(len(baseDeconverted)/8)\n",
    "    \n",
    "    for i in range (0, characterLength):\n",
    "        characterWhole = baseDeconverted[i*8:(i+1)*8]\n",
    "        characterIndexSeq = characterWhole[0:6]\n",
    "        corrected_data += characterIndexSeq\n",
    "        characterPointerSeq = characterWhole[6]\n",
    "        corrected_data += characterPointerSeq\n",
    "    \n",
    "    # Count matched sequence after RS correction\n",
    "    for m in range (0, 40):\n",
    "        for n in range (0, 100):\n",
    "            if corrected_data == array_data_payload[m][n]:\n",
    "                dataStrandsOccup[Chapter][Segment] = 1\n",
    "                read_index_3.append(read_index_1[read_number])   # Store Read Number with successful decoding attempt after RS correction\n",
    "    \n",
    "    candi_dataStrands[Chapter][Segment].append(corrected_data) # Store the RS-corrected sequence in candidate sequence list\n",
    "\n",
    "\n",
    "for m in range (0, 40):\n",
    "    for n in range (0, 100):\n",
    "        if (dataStrands[m][n] == None):\n",
    "            try:\n",
    "                dataStrands[m][n] = most_frequent(candi_dataStrands[m][n])  # Only keep the sequence appearing most frequently\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "for m in range (0, 40):\n",
    "    for n in range (0, 100):      \n",
    "        if (dataStrands[m][n] != None):\n",
    "            baseDeconverted = dataStrands[m][n]  \n",
    "            getSegmentData = []\n",
    "            characterLength = int(len(baseDeconverted)/7)\n",
    "            for i in range (0, characterLength):\n",
    "                characterWhole = baseDeconverted[i*7:(i+1)*7]\n",
    "                characterIndexSeq = characterWhole[0:6]\n",
    "                characterPointerSeq = characterWhole[6]\n",
    "                ternaryCharacterIndex = oligoToBase3(characterIndexSeq)\n",
    "                if (ternaryCharacterIndex == -1):\n",
    "                    continue\n",
    "                characterIndex = ternaryToDecimal(ternaryCharacterIndex)   # Convert ternary Index Number to decimal number\n",
    "\n",
    "                if (characterIndex > 720):\n",
    "                    continue\n",
    "\n",
    "                # Locate Combination by looking up the Index Number and Pointer from the decoded Reference Strands\n",
    "                getReference = []\n",
    "                for i in range (0, len(referenceStrands)):\n",
    "                    getReference.append(referenceStrands[i][characterIndex])\n",
    "                getReference = ''.join(getReference)\n",
    "                getCharacterData = [None]*16\n",
    "                for i in range (0, len(getReference)):\n",
    "                    if getReference[i] == characterPointerSeq:\n",
    "                        getCharacterData[i] = '1'\n",
    "                    else:\n",
    "                        getCharacterData[i] = '0'\n",
    "                getCharacterData = ''.join(getCharacterData)\n",
    "                getSegmentData.append(getCharacterData)\n",
    "            getSegmentData = ''.join(getSegmentData)\n",
    "\n",
    "\n",
    "            # Eliminate redundant '00100000's which adds up oligo length to ensure the quality of batch production in oligo synthesis\n",
    "            while (len(getSegmentData) > 0):\n",
    "                if (getSegmentData[-16:-8] == '00100000'):\n",
    "                    getSegmentData = getSegmentData[0: len(getSegmentData)-8]\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # Convert binary data to hex data\n",
    "            getSegmentData_hex = binaryToHex(getSegmentData)\n",
    "\n",
    "            # Convert hex data to ASCII texts\n",
    "            try:\n",
    "                getSegmentData_text = hexToText(getSegmentData_hex)\n",
    "                dataStrandstoText[m][n] = getSegmentData_text \n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "for i in range (0, len(dataStrandstoText)):\n",
    "    \n",
    "    text = ''\n",
    "    for j in range (0, len(dataStrandstoText[i])):\n",
    "        try:\n",
    "            text += dataStrandstoText[i][j]\n",
    "        except:\n",
    "            pass\n",
    "    if (text != ''):\n",
    "        print('This is Chapter ' + str(i))\n",
    "        print(text)\n",
    "\n",
    "\n",
    "for i in range (0, len(dataStrandsOccup)):\n",
    "    for j in range (0, len(dataStrandsOccup[i])):\n",
    "        if dataStrandsOccup[i][j] == 1:\n",
    "            if dataStrandsOccup[i][j+1] == None: \n",
    "                print('Chapter ' + str(i) + \" is found\")\n",
    "                print(\"Last segment is \" + str(j))\n",
    "                break\n",
    "    \n",
    "    \n",
    "# Get the number of successfully decoded reads before and after RS correction    \n",
    "res_read_index_2 = [*set(read_index_2)]\n",
    "res_read_index_3 = [*set(read_index_3)]\n",
    "print('Total number of valid reads: ' + str(len(res_read_index_1)))\n",
    "print('Exact matched sequences before RS correction: ' + str(len(res_read_index_2)))\n",
    "print('Matched sequences after RS correction: ' + str(len(res_read_index_3)))\n",
    "\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
